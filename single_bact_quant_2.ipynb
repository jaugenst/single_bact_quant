{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3fd5c3e-1f24-4d7b-b3ce-69f6fc9e8f61",
   "metadata": {},
   "source": [
    "### Modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe0416-4a48-461a-8a16-4b092aa8c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models, io\n",
    "from cellpose.io import *\n",
    "from collections import defaultdict\n",
    "import geopandas\n",
    "import glob\n",
    "import imagej\n",
    "from jpype import JArray, JInt\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "from pathlib import Path\n",
    "import scyjava\n",
    "import seaborn\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "import random\n",
    "from math import isnan \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QWidget, QScrollArea, QLabel, QGridLayout\n",
    "from PyQt5.QtGui import QPixmap\n",
    "from PyQt5.QtCore import Qt\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b05f3-3b0f-4934-b606-f4add107d4e5",
   "metadata": {},
   "source": [
    "### Initialization of Fiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdc313-f158-488a-9ef2-0e1ff8d1aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "scyjava.config.add_option('-Xmx60g')\n",
    "ij = imagej.init('/Users/MrWor/Documents/Fiji.app', mode='interactive')\n",
    "ij.ui().showUI()\n",
    "ij.getVersion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ce273-a9ab-4b23-afe9-3d5ef3b4eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different plugin needed for the workflow\n",
    "showPolygonRoi = scyjava.jimport('ij.gui.PolygonRoi')\n",
    "Overlay = scyjava.jimport('ij.gui.Overlay')\n",
    "Regions = scyjava.jimport('net.imglib2.roi.Regions')\n",
    "LabelRegions = scyjava.jimport('net.imglib2.roi.labeling.LabelRegions')\n",
    "ZProjector = scyjava.jimport('ij.plugin.ZProjector')()\n",
    "Duplicator = scyjava.jimport('ij.plugin.Duplicator')()\n",
    "ov = Overlay()\n",
    "Model =  scyjava.jimport('fiji.plugin.trackmate.Model')\n",
    "Settings= scyjava.jimport('fiji.plugin.trackmate.Settings')\n",
    "TrackMate = scyjava.jimport('fiji.plugin.trackmate.TrackMate')\n",
    "Settings= scyjava.jimport('fiji.plugin.trackmate.Settings')\n",
    "TrackMate = scyjava.jimport('fiji.plugin.trackmate.TrackMate')\n",
    "Logger= scyjava.jimport('fiji.plugin.trackmate.Logger')\n",
    "DetectorKeys= scyjava.jimport('fiji.plugin.trackmate.detection.DetectorKeys') \n",
    "ExportTracksToXML= scyjava.jimport('fiji.plugin.trackmate.action.ExportTracksToXML') \n",
    "TmXmlWriter= scyjava.jimport('fiji.plugin.trackmate.io.TmXmlWriter')\n",
    "LogRecorder = scyjava.jimport('fiji.plugin.trackmate.util.LogRecorder')\n",
    "SparseLAPTrackerFactory= scyjava.jimport('fiji.plugin.trackmate.tracking.jaqaman.SparseLAPTrackerFactory')\n",
    "TMUtils = scyjava.jimport('fiji.plugin.trackmate.util.TMUtils')\n",
    "HyperStackDisplayer = scyjava.jimport('fiji.plugin.trackmate.visualization.hyperstack.HyperStackDisplayer')\n",
    "SelectionModel = scyjava.jimport('fiji.plugin.trackmate.SelectionModel')\n",
    "CellposeDetectorFactory = scyjava.jimport('fiji.plugin.trackmate.cellpose.CellposeDetectorFactory')\n",
    "FeatureFilter = scyjava.jimport('fiji.plugin.trackmate.features.FeatureFilter')\n",
    "DisplaySetting = scyjava.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettings')\n",
    "DisplaySettingsIO = scyjava.jimport('fiji.plugin.trackmate.gui.displaysettings.DisplaySettingsIO')\n",
    "CaptureOverlayAction = scyjava.jimport('fiji.plugin.trackmate.action.CaptureOverlayAction')\n",
    "PretrainedModel= scyjava.jimport('fiji.plugin.trackmate.cellpose.CellposeSettings.PretrainedModel')\n",
    "ThresholdDetectorFactory= scyjava.jimport('fiji.plugin.trackmate.detection.ThresholdDetectorFactory')\n",
    "TrackScheme = scyjava.jimport('fiji.plugin.trackmate.visualization.trackscheme.TrackScheme')\n",
    "TrackTableView = scyjava.jimport('fiji.plugin.trackmate.visualization.table.TrackTableView')\n",
    "AllSpotsTableView = scyjava.jimport('fiji.plugin.trackmate.visualization.table.AllSpotsTableView')\n",
    "\n",
    "rm = ij.RoiManager.getRoiManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7bea3-1676-467f-aa71-d4149952aa93",
   "metadata": {},
   "source": [
    "### Function used for the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d623d5d-c280-4145-a92d-25ffd3f0b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bacteria_area(bact_path, directory_path, threshold_low, threshold_high, distance, known, unit):\n",
    "    # Iterate over the folders and process each folder\n",
    "    w = scyjava.jimport('ij.WindowManager')\n",
    "    file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    for file_path in file_list:\n",
    "        rm.runCommand(\"Reset\")\n",
    "        basename = os.path.basename(file_path)\n",
    "        corename = os.path.splitext(basename)[0]\n",
    "        image_path = f\"{bact_path}bact_channel_{corename}.tif\"\n",
    "        basename2 = os.path.basename(image_path)\n",
    "        imp = ij.IJ.openImage(image_path)\n",
    "        print(f\"Opening {image_path}\")\n",
    "        ij.IJ.run(imp, \"Smooth\", \"stack\")\n",
    "        ij.IJ.run(imp, \"Smooth\", \"stack\")\n",
    "        imp.show()\n",
    "        ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known} unit={unit}\");')    \n",
    "        ij.IJ.run(\"Set Measurements...\", f'area limit redirect=None decimal=2')\n",
    "        ij.IJ.setAutoThreshold(imp, \"Default dark\")\n",
    "        ij.IJ.setRawThreshold(imp, threshold_low, threshold_high)\n",
    "        ij.IJ.run(imp, \"Convert to Mask\", \"background=Dark black\");\n",
    "        input_ROI = Path(f\"{voronoi_path}/{corename}_voronoi.zip\")\n",
    "        rm.open(f\"{input_ROI}\")\n",
    "        roi_count = rm.getCount()\n",
    "        for i in range(0, roi_count-1):\n",
    "            rm.select(i)\n",
    "            ij.IJ.run(imp, \"Analyze Particles...\", f\"summarize stack\");\n",
    "        window_name = f\"Summary of {basename2}\"\n",
    "        ij.IJ.selectWindow(window_name)\n",
    "        ij.IJ.renameResults(f\"{window_name}\", \"Results\")\n",
    "        output_path = Path(f\"{bact_path}{corename}_area_summary.csv\").as_posix()\n",
    "        ij.IJ.saveAs(\"Results\", output_path)\n",
    "        ij.IJ.run(\"Clear Results\")\n",
    "        w.getWindow(\"Results\").close()\n",
    "        rm.runCommand(\"Reset\")\n",
    "        ij.py.run_macro('close(\"*\");')\n",
    "            \n",
    "\n",
    "def track_bacteria(directory_path, bact_path, dsettings, quality_filter, tsettings, display=False):\n",
    "    '''\n",
    "    This function leverages ImageJ's Trackmate plugin to track the bacteria within each single-cell video provided in the input folder bact. \n",
    "    It uses the Tresholding Detector for segmentation (with detection parameters specified in dsettings), and the LAP Tracker algorithm for tracking (with tracking parameters specified in tsettings). The function also takes as input the desired quality filter on the detected spots.\n",
    "    The function saves the Trackmate XML model as well as a CSV file of the tracks for each cell in bact/Output/.\n",
    "    '''\n",
    "    out = bact_path+\"Output/\"\n",
    "    if not os.path.exists(out):\n",
    "        os.makedirs(out)\n",
    "    for image in os.listdir(bact_path):\n",
    "        basename = os.path.basename(image)\n",
    "        if basename.startswith('bact'):\n",
    "            if not image.endswith(\"overlay.tif\"):\n",
    "                if (image[len(image)-4:] == \".tif\"):\n",
    "                    # Open Image\n",
    "                    imp = ij.IJ.openImage(bact_path + image)\n",
    "                    print(f\"Trackmate is opening {image}\")\n",
    "                    imp.show()\n",
    "                    ij.IJ.run(imp, \"Select None\", \"\")\n",
    "                    ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known} unit={unit}\");')\n",
    "                    ij.IJ.run(\"Smooth\", \"stack\")\n",
    "                    ij.IJ.run(\"Smooth\", \"stack\")\n",
    "                    # Create Model\n",
    "                    model = Model()\n",
    "                    settings = Settings(imp)\n",
    "                    # Detector\n",
    "                    settings.detectorFactory = ThresholdDetectorFactory()\n",
    "                    for parameter, value in dsettings.items():\n",
    "                        settings.detectorSettings[parameter] = value\n",
    "                    filter1 = FeatureFilter('QUALITY', quality_filter, True)\n",
    "                    settings.addSpotFilter(filter1)\n",
    "                    #print(settings.detectorSettings)\n",
    "                    # Tracker\n",
    "                    settings.trackerFactory = SparseLAPTrackerFactory()\n",
    "                    settings.trackerSettings = settings.trackerFactory.getDefaultSettings()\n",
    "                    for parameter, value in tsettings.items():\n",
    "                        settings.trackerSettings[parameter] = value\n",
    "                    # Execute Tracking\n",
    "                    trackmate = TrackMate(model, settings)\n",
    "                    ok = trackmate.checkInput()\n",
    "                    if not ok:\n",
    "                        sys.exit(str(trackmate.getErrorMessage()))\n",
    "                    ok = trackmate.process()\n",
    "                    if not ok:\n",
    "                        #sys.exit(str(trackmate.getErrorMessage()))\n",
    "                        print(str(trackmate.getErrorMessage()))\n",
    "                        ij.py.run_macro('close(\"*\");')\n",
    "                    \n",
    "                    selectionModel = SelectionModel(model)\n",
    "                    # Display\n",
    "                    ds = DisplaySettingsIO.readUserDefault()\n",
    "                    if display:\n",
    "                        displayer = HyperStackDisplayer(model, selectionModel, imp, ds)\n",
    "                        displayer.render()\n",
    "                        displayer.refresh()\n",
    "                        trackscheme = TrackScheme(model, selectionModel, ds)\n",
    "                        trackscheme.render()\n",
    "                    # Save Data\n",
    "                    basename_image = os.path.basename(image)\n",
    "                    corename = os.path.splitext(basename_image)[0]\n",
    "                    outFile = Path(out+corename+\"_exportModel.xml\")\n",
    "                    writer = TmXmlWriter(outFile)\n",
    "                    writer.appendModel(model)\n",
    "                    writer.appendSettings(settings)\n",
    "                    writer.writeToFile()\n",
    "                    csvFileSpots = out+corename+\"_exportTracks.csv\"\n",
    "                    spotsTableView = AllSpotsTableView(model, selectionModel, ds, image)\n",
    "                    spotsTableView.exportToCsv(csvFileSpots)\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "    \n",
    "def merge_trackmate_rois(bact_path, directory_path, grouped_SC):\n",
    "    '''\n",
    "    This function seeks to assign bacterial ROIs to tracks by merging the results of tracking (via Trackmate) and ROI detection (via Thresholding in ImageJ). It matches ROIs to spots detected in Trackmate based on the nearest centroid.\n",
    "    For each cell, the function saves a CSV file of tracks and their corresponding ROIs in a folder called grouped.\n",
    "    '''\n",
    "    file_pattern = os.path.join(bact_path, \"*.tif\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    for file_path in file_list:\n",
    "        basename = os.path.basename(file_path)\n",
    "        if basename.startswith('bact'):\n",
    "            if not file_path.endswith(\"overlay.tif\"):\n",
    "                filename = os.path.basename(file_path)\n",
    "                filename2 = os.path.splitext(filename)[0]\n",
    "                first = Path(f\"{bact_path}/Output/{filename2}_exportTracks.csv\").as_posix()                \n",
    "                second = Path(f\"{bact_path}/{filename2}_bactROI.csv\").as_posix()\n",
    "                if os.path.exists(first) and os.path.exists(second):\n",
    "                    df_first = pandas.read_csv(first)\n",
    "                    df_first = df_first.drop([0,1,2])\n",
    "                    if len(df_first)>0:\n",
    "                        print(f\"{filename2}_exportTracks.csv is not empty\")\n",
    "                        pairwise = xref_locations(first, second, \n",
    "                                              first_x='POSITION_X', \n",
    "                                              first_y='POSITION_Y', \n",
    "                                              first_z='POSITION_Z', \n",
    "                                              second_x='X', \n",
    "                                              second_y='Y', \n",
    "                                              second_z='Slice',\n",
    "                                              max_dist=100,\n",
    "                                              verbose=False)\n",
    "                        grouped = pairwise[['ID', pairwise.columns[12]]].reset_index(drop=True)\n",
    "                        grouped.rename(columns={'index_right': 'object_ID_list'}, inplace=True)\n",
    "                        final_csv = Path(f\"{grouped_SC}{filename2}_grouped.csv\")\n",
    "                        grouped.to_csv(final_csv)\n",
    "                        print(f\"Saving {final_csv}\")\n",
    "                        final_csv2 = Path(f\"{grouped_SC}{filename2}_pairwise.csv\")\n",
    "                        pairwise.to_csv(final_csv2)\n",
    "                    else:\n",
    "                        print(f\"{filename2}_exportTracks.csv is empty\")\n",
    "\n",
    "\n",
    "def xref_locations(first, second, first_x='POSITION_X', first_y='POSITION_Y', first_z='POSITION_Z',\n",
    "                   second_x='X', second_y='Y', second_z='Slice',\n",
    "                   max_dist=5, verbose=False):\n",
    "    pairwise_elements = pandas.DataFrame()\n",
    "    first_measurements = pandas.read_csv(first)\n",
    "    first_measurements = first_measurements.drop([0,1,2])\n",
    "    second_measurements = pandas.read_csv(second)\n",
    "    first_gdf = geopandas.GeoDataFrame(\n",
    "        first_measurements,\n",
    "        geometry=geopandas.points_from_xy(first_measurements[first_x],\n",
    "                                          first_measurements[first_y],\n",
    "                                          first_measurements[first_z]))\n",
    "    second_gdf = geopandas.GeoDataFrame(\n",
    "        second_measurements,\n",
    "        geometry=geopandas.points_from_xy(second_measurements[second_x],\n",
    "                                          second_measurements[second_y],\n",
    "                                          second_measurements[second_z]))\n",
    "    ti_rows = first_gdf.shape[0]\n",
    "    tj_rows = second_gdf.shape[0]\n",
    "    for ti_row in range(0, ti_rows):\n",
    "        if verbose:\n",
    "            print(f\"On row: {ti_row}\")\n",
    "        ti_element = first_gdf.iloc[[ti_row, ]]\n",
    "        \n",
    "        titj = geopandas.sjoin_nearest(ti_element, second_gdf,\n",
    "                                       distance_col=\"pairwise_dist\",\n",
    "                                       max_distance=max_dist)\n",
    "        chosen_closest_dist = titj.pairwise_dist.min()\n",
    "        if (isnan(chosen_closest_dist)):\n",
    "            print(f\"This element has no neighbor within {max_dist}.\")\n",
    "        else:\n",
    "            chosen_closest_cell = titj.pairwise_dist == chosen_closest_dist\n",
    "            chosen_closest_row = titj[chosen_closest_cell]\n",
    "            pairwise_tmp = pandas.concat([pairwise_elements, chosen_closest_row])\n",
    "            pairwise_elements = pairwise_tmp\n",
    "    return pairwise_elements\n",
    "\n",
    "def apply_bact_overlays(bact_path, grouped):\n",
    "    '''\n",
    "    This function allows for visual quality-control of the bacterial-tracking step by adding colored overlays to the bacterial tracks in each single-cell video. Bacterial clusters of the same track remain the same color from frame to frame.\n",
    "    All of the overlayed videos are saved in the folder bact with the title [cell_number]_overlay.tif.\n",
    "    '''\n",
    "    file_pattern = os.path.join(bact_path, \"*.tif\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    colors = [\"blue\", \"cyan\", \"green\", \"magenta\", \"orange\", \"red\", \"yellow\"]\n",
    "    for file_path in file_list:\n",
    "        f_name = os.path.basename(file_path)\n",
    "        if f_name.startswith('bact'):\n",
    "            if not file_path.endswith(\"overlay.tif\"):\n",
    "                f_name = os.path.basename(file_path)\n",
    "                print(f\"opening {f_name}\")\n",
    "                f_name = os.path.splitext(f_name)[0]\n",
    "                imp = ij.IJ.openImage(file_path)\n",
    "                ij.ui().show(imp)\n",
    "                ij.IJ.run(imp, \"Select None\", \"\")\n",
    "                input_csv = Path(f\"{grouped}/{f_name}_grouped.csv\")\n",
    "                if os.path.exists(input_csv):\n",
    "                    df = pandas.read_csv(input_csv)\n",
    "                    pouet = df['object_ID_list']\n",
    "                    input_ROI = Path(f\"{bact_path}/{f_name}_bactROI.zip\")\n",
    "                    if not os.path.exists(input_ROI):\n",
    "                        input_ROI = Path(f\"{bact_path}/{f_name}_bactROI.roi\")\n",
    "                    rm.open(f\"{input_ROI}\")\n",
    "                    for i in range(len(pouet)):\n",
    "                        cell = df['object_ID_list'][i]\n",
    "                        cell_index = int(cell)\n",
    "                        random_color = random.choice(colors)\n",
    "                        rm.select(cell_index)\n",
    "                        print(f\"selecting ROI {cell_index}\")\n",
    "                        imp.getRoi()\n",
    "                        roi = imp.getRoi()  \n",
    "                        if roi is None:\n",
    "                            roi_number = ij.py.to_java(str(cell_index))\n",
    "                            selection = f\"roiManager('Select', {roi_number});\"\n",
    "                            ij.py.run_macro(selection)\n",
    "                        overlay_command = f\"Overlay.addSelection('{random_color}',2);\"\n",
    "                        ij.py.run_macro(overlay_command)\n",
    "                    ij.py.run_macro(\"setMinAndMax(0, 100);\")\n",
    "                    ij.py.run_macro(\"run('Flatten', 'stack');\")\n",
    "                    method = 'max all'\n",
    "                    z_projector_result = ZProjector.run(imp, method)\n",
    "                    z_collapsed_image = ij.py.from_java(z_projector_result)\n",
    "                    z_collapsed_dataset = ij.py.to_dataset(z_projector_result)\n",
    "                    result_path = os.path.splitext(file_path)[0] + \"_overlay.tif\"\n",
    "                    if os.path.exists(result_path):\n",
    "                        os.remove(result_path)\n",
    "                    saved = ij.io().save(z_collapsed_dataset, result_path)       \n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "                    rm.runCommand(\"Reset\")\n",
    "                else:\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "                    rm.runCommand(\"Reset\")                    \n",
    "\n",
    "\n",
    "\n",
    "def calculate_total_volume_per_cell(df):\n",
    "    \"\"\"Calculates the sum of the \"Total Area\" for each pattern of the \"Slice\" column.\n",
    "\n",
    "    Args:\n",
    "        df: A pandas DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the sum of the \"Total Area\" for each pattern of the \"Slice\" column.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a list to store the DataFrames with results.\n",
    "    results = []\n",
    "\n",
    "    # Loop through the DataFrame.\n",
    "    for i in range(len(df)):\n",
    "        # If the current cell value in the \"Slice\" column is 1,\n",
    "        if df['Slice'][i] == 1:\n",
    "            # Sum the \"Total Area\" column for the next 10 rows.\n",
    "            #slice_number = 10  # You need to define slice_number and slice_distance\n",
    "            #slice_distance = 1  # You need to define slice_number and slice_distance\n",
    "            bacterial_area = df['Total Area'][i:i + slice_number].sum()\n",
    "            bacterial_volume = bacterial_area * slice_distance\n",
    "            # Create a DataFrame with the current pattern number and the total area.\n",
    "            result_df = pandas.DataFrame({'bacterial_volume': [bacterial_volume]}, index=[i])\n",
    "            results.append(result_df)\n",
    "\n",
    "    # Concatenate the list of DataFrames to create the final results DataFrame.\n",
    "    final_results = pandas.concat(results, ignore_index=True)\n",
    "\n",
    "    # Return the final results DataFrame.\n",
    "    return final_results\n",
    "\n",
    "def single_cell_isolation(cois, directory_path, bact_path, voronoi_path, channels_path, size_limit = 1):\n",
    "    file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    final_results_path = f\"{directory_path}final_results/\"\n",
    "    for file_path in file_list:\n",
    "        f_name = os.path.basename(file_path)\n",
    "        corename = os.path.splitext(f_name)[0]\n",
    "        single_cell_path = f\"{directory_path}single_cells/{corename}/\"\n",
    "        if not os.path.exists(single_cell_path):\n",
    "            os.makedirs(single_cell_path)\n",
    "        roi_path = f\"{voronoi_path}{corename}_voronoi.zip\"\n",
    "        burden_csv = f\"{final_results_path}/{corename}_burden.csv\"\n",
    "        df = pandas.read_csv(burden_csv)\n",
    "        rm.open(roi_path)\n",
    "        for channel in cois:\n",
    "            if channel.startswith(\"bact\"):\n",
    "                image_path = f\"{bact_path}{channel}_{corename}.tif\"\n",
    "            else:\n",
    "                image_path = f\"{channels_path}{channel}_{corename}.tif\"\n",
    "            imp = ij.IJ.openImage(image_path)\n",
    "            imp.show()\n",
    "            #imp.setSlice(4)\n",
    "            #roi_count = rm.getCount()\n",
    "            #for n in range(roi_count-1):\n",
    "            for index, row in df.iterrows():\n",
    "                if row[\"bacterial_volume\"] > size_limit:\n",
    "                    rm.select(index)\n",
    "                    cell_name = f\"{channel}_{corename}_{index}\"\n",
    "                    ij.IJ.run(\"Duplicate...\", f\"title={str(cell_name)} duplicate\")\n",
    "                    ij.IJ.run(\"Clear Outside\", \"stack\")\n",
    "                    new_vid =  w.getImage(str(cell_name))\n",
    "                    ij.IJ.save(new_vid, single_cell_path + cell_name + \".tif\")\n",
    "                    w.getImage(str(cell_name)).close()\n",
    "            ij.py.run_macro('close(\"*\");')\n",
    "        rm.runCommand(\"Reset\")\n",
    "\n",
    "def single_composite_isolation(cois, directory_path, voronoi_path, size_limit = 1):\n",
    "    file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    final_results_path = f\"{directory_path}final_results/\"\n",
    "    for file_path in file_list:\n",
    "        f_name = os.path.basename(file_path)\n",
    "        corename = os.path.splitext(f_name)[0]\n",
    "        roi_path = f\"{voronoi_path}{corename}_voronoi.zip\"\n",
    "        burden_csv = f\"{final_results_path}/{corename}_burden.csv\"\n",
    "        df = pandas.read_csv(burden_csv)\n",
    "        rm.open(roi_path)\n",
    "        imp = ij.IJ.openImage(file_path)\n",
    "        imp.show()\n",
    "        imp.setDisplayMode(1)\n",
    "        for index, row in df.iterrows():\n",
    "            if row[\"bacterial_volume\"] > size_limit:\n",
    "                cell_name = f\"{corename}_{index}\"\n",
    "                output_path = f\"{directory_path}single_cells/{corename}/rois_bact/{cell_name}/\"\n",
    "                if os.path.exists(output_path):\n",
    "                    rm.select(index)\n",
    "                    ij.IJ.run(\"Duplicate...\", f\"title={str(cell_name)} duplicate\")\n",
    "                    ij.IJ.run(\"Clear Outside\", \"stack\")\n",
    "                    new_vid =  w.getImage(str(cell_name))             \n",
    "                    ij.IJ.save(new_vid, output_path + cell_name + \".tif\")\n",
    "                    w.getImage(str(cell_name)).close()\n",
    "        ij.py.run_macro('close(\"*\");')\n",
    "        rm.runCommand(\"Reset\")\n",
    "\n",
    "def get_bact_rois(bact_path):\n",
    "    file_pattern = os.path.join(bact_path, \"*.tif\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    for file_path in file_list:\n",
    "        f_name = os.path.basename(file_path)\n",
    "        if f_name.startswith('bact'):\n",
    "            if not file_path.endswith('overlay.tif'):\n",
    "                imp = ij.IJ.openImage(file_path)\n",
    "                f_name = os.path.basename(file_path)\n",
    "                f_name = os.path.splitext(f_name)[0]\n",
    "                imp.show()\n",
    "                ij.IJ.run(imp, \"Select None\", \"\")\n",
    "                ij.IJ.run(\"Smooth\", \"stack\")\n",
    "                ij.IJ.run(\"Smooth\", \"stack\")\n",
    "                ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known_scale} unit={unit}\");')    \n",
    "                ij.IJ.run(\"Set Measurements...\", f'area centroid stack decimal=2')\n",
    "                ij.IJ.setAutoThreshold(imp, \"Default dark\")\n",
    "                ij.IJ.setRawThreshold(imp, threshold_low, threshold_high)\n",
    "                ij.IJ.run(imp, \"Convert to Mask\", \"background=Dark black\");\n",
    "                ij.IJ.run(imp, \"Analyze Particles...\", f\"size={threshold_size}-Infinity display add stack\");\n",
    "                #ij.IJ.run(imp, \"Measure\", \"\");\n",
    "                roi_count = rm.getCount()\n",
    "                if roi_count == 0:\n",
    "                    print(f\"this {f_name} has no bacteria\")\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "                elif roi_count == 1:\n",
    "                    rm.save(f\"{bact_path}\" + f\"{f_name}_bactROI.roi\")\n",
    "                    output_path = Path(f\"{bact_path}{f_name}_bactROI.csv\").as_posix()\n",
    "                    ij.IJ.saveAs(\"Results\", output_path)\n",
    "                    ij.IJ.run(\"Clear Results\")\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "                    rm.runCommand(\"Reset\")                    \n",
    "                else:\n",
    "                    rm.save(f\"{bact_path}\" + f\"{f_name}_bactROI.zip\")\n",
    "                    output_path = Path(f\"{bact_path}{f_name}_bactROI.csv\").as_posix()\n",
    "                    ij.IJ.saveAs(\"Results\", output_path)\n",
    "                    ij.IJ.run(\"Clear Results\")\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "                    rm.runCommand(\"Reset\")\n",
    "\n",
    "def circlesofhell(bact_roi_path, channel, distance, known_scale, unit, imp):\n",
    "    roi_pattern = os.path.join(bact_roi_path, \"*.roi\")\n",
    "    roi_list = glob.glob(roi_pattern)\n",
    "    for roi in roi_list:\n",
    "        roi_basename = os.path.basename(roi)\n",
    "        roi_corename = os.path.splitext(roi_basename)[0]\n",
    "        open_roi = rm.open(roi)\n",
    "        rm.select(0)\n",
    "        enlarged = ij.IJ.run(\"Enlarge...\", \"enlarge=1 pixel\")\n",
    "        rm.addRoi(enlarged)\n",
    "        for n in range(0,3):\n",
    "            rm.select(1+n)\n",
    "            enlarged = ij.IJ.run(\"Enlarge...\", \"enlarge=1 pixel\")\n",
    "            rm.addRoi(enlarged)\n",
    "        rm.select(0)\n",
    "        ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known_scale} unit={unit}\");')  \n",
    "        ij.IJ.run(\"Measure\")\n",
    "        imp.removeScale()\n",
    "        ij.IJ.run(\"Make Band...\", \"band=1\")\n",
    "        ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known_scale} unit={unit}\");')  \n",
    "        ij.IJ.run(\"Measure\")\n",
    "        imp.removeScale()\n",
    "        for n in range(0,4):\n",
    "            rm.select(1+n)\n",
    "            ij.IJ.run(\"Make Band...\", \"band=1\")\n",
    "            ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known_scale} unit={unit}\");')  \n",
    "            ij.IJ.run(\"Measure\")\n",
    "            imp.removeScale()\n",
    "        rm.runCommand(\"Reset\")\n",
    "        output_path = f\"{bact_roi_path}/{roi_corename}_{channel}.csv\"\n",
    "        saving = ij.IJ.saveAs(\"Results\", output_path)\n",
    "        ij.IJ.run(\"Clear Results\")\n",
    "\n",
    "def saving_rois(bact_path):\n",
    "    #Saving ROIs indidually into a separate folder\n",
    "    file_pattern = os.path.join(bact_path, \"*.tif\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    for file_path in file_list:\n",
    "        if not file_path.endswith('overlay.tif'):\n",
    "            basename = os.path.basename(file_path)\n",
    "            corename = os.path.splitext(basename)[0]\n",
    "            if basename.startswith(\"bact\"):\n",
    "                corename2 = corename.split(\"bact_channel_\")[1]\n",
    "                imp = ij.IJ.openImage(file_path)\n",
    "                ij.ui().show(imp)\n",
    "                input_csv = Path(f\"{grouped_SC}/{corename}_grouped.csv\")\n",
    "                if os.path.exists(input_csv):\n",
    "                    bact_roi_path = bact_path + f\"rois_bact/{corename2}\"\n",
    "                    if not os.path.exists(bact_roi_path):\n",
    "                        os.makedirs(bact_roi_path)\n",
    "                    df = pandas.read_csv(input_csv)\n",
    "                    pouet = df['object_ID_list']\n",
    "                    input_ROI = Path(f\"{bact_path}/{corename}_bactROI.zip\")\n",
    "                    if not os.path.exists(input_ROI):\n",
    "                        input_ROI = Path(f\"{bact_path}/{corename}_bactROI.roi\")\n",
    "                    rm.open(f\"{input_ROI}\")\n",
    "                    for i in range(len(pouet)):\n",
    "                        cell = df['object_ID_list'][i]\n",
    "                        cell_index = int(cell)\n",
    "                        rm.select(cell_index)\n",
    "                        output = f\"{bact_roi_path}/{cell_index}.roi\"\n",
    "                        saved = rm.runCommand(\"Save\", output)\n",
    "                    rm.runCommand(\"Reset\")\n",
    "                    ij.py.run_macro('close(\"*\");')\n",
    "\n",
    "def single_cell_fluorescence(cois, directory_path, voronoi_path, channels_path, distance, known_scale, unit, size_limit = 1):\n",
    "    file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "    file_list = glob.glob(file_pattern)\n",
    "    final_results_path = f\"{directory_path}final_results/\"\n",
    "    set_string = f'Set Measurements...'\n",
    "    measure_string = f'mean area limit integrated redirect=None decimal=2'\n",
    "    for file_path in file_list:\n",
    "        f_name = os.path.basename(file_path)\n",
    "        corename = os.path.splitext(f_name)[0]\n",
    "        roi_path = f\"{voronoi_path}{corename}_voronoi.zip\"\n",
    "        burden_csv = f\"{final_results_path}/{corename}_burden.csv\"\n",
    "        df = pandas.read_csv(burden_csv)\n",
    "        rm.open(roi_path)\n",
    "        for channel_name in cois:\n",
    "            image_path = f\"{channels_path}{channel_name}_{corename}.tif\"\n",
    "            basename2 = os.path.basename(image_path)\n",
    "            corename2 = os.path.splitext(basename2)[0]\n",
    "            cell_list = []\n",
    "            imp = ij.IJ.openImage(image_path)\n",
    "            imp.show()\n",
    "            imp.setSlice(4)\n",
    "            duplicated = ij.IJ.run(\"Duplicate...\", \"slice\")\n",
    "            duplicated_image = f\"{corename2}-1.tif\"\n",
    "            ij.IJ.selectWindow(duplicated_image)\n",
    "            new_image = w.getImage(duplicated_image)\n",
    "            ij.py.run_macro(f'run(\"Set Scale...\", \"distance={distance} known={known_scale} unit={unit}\");')\n",
    "            ij.IJ.setRawThreshold(new_image, threshold_low, threshold_high)\n",
    "            ij.IJ.run(set_string, measure_string)\n",
    "            for index, row in df.iterrows():\n",
    "                if row[\"bacterial_volume\"] > size_limit:\n",
    "                    rm.select(index)\n",
    "                    ij.IJ.run(\"Measure\")\n",
    "                    cell_name = f\"{channel_name}_{corename}_{index}\"\n",
    "                    cell_list.append(cell_name)\n",
    "            output_path = f\"{channels_path}{corename2}_number.csv\"\n",
    "            ij.IJ.saveAs(\"Results\", output_path)\n",
    "            \n",
    "            #Getting the numbers\n",
    "            norm_raw = []\n",
    "            df_number = pandas.read_csv(output_path)\n",
    "            for i in range(len(df_number)):\n",
    "                ratio = df_number['RawIntDen'][i] / df_number['Area'][i]\n",
    "                norm_raw.append(ratio)\n",
    "            df_number['RawIntDen/Area'] = norm_raw  \n",
    "            df_cell = pandas.DataFrame()\n",
    "            df_cell['cell_ID'] = cell_list\n",
    "            df_cell['RawIntDen/Area'] = df_number['RawIntDen/Area']\n",
    "            output_path2 = f\"{channels_path}{channel_name}_{corename}_final_number.csv\"\n",
    "            df_cell.to_csv(output_path2)\n",
    "\n",
    "            #clearing the place\n",
    "            ij.py.run_macro('close(\"*\");')\n",
    "            ij.IJ.run(\"Clear Results\")\n",
    "        rm.runCommand(\"Reset\")\n",
    "\n",
    "def df_cleaning(df):\n",
    "    df_transposed = df.transpose()\n",
    "    df_cleaned = df_transposed.drop([\"Unnamed: 0\",\"circle\"])\n",
    "    df_cleaned.rename(columns={df_cleaned.columns[0]: 'd0', \n",
    "                               df_cleaned.columns[1]: 'd1',  \n",
    "                               df_cleaned.columns[2]: 'd2', \n",
    "                               df_cleaned.columns[3]: 'd3', \n",
    "                               df_cleaned.columns[4]: 'd4', \n",
    "                               df_cleaned.columns[5]: 'd5'}, inplace=True)\n",
    "    df_cleaned_sorted = df_cleaned.sort_index()\n",
    "    df_norm = df_cleaned_sorted.sub(df_cleaned_sorted.mean(axis=1), axis=0)\n",
    "    df_norm.head()\n",
    "    for idx, row in df_norm.iterrows():\n",
    "        plt.plot(range(len(row)),row)\n",
    "    plt.xlabel('distance (pixels)')\n",
    "    plt.ylabel('RawIntDen / Area')\n",
    "    #plt.legend()\n",
    "    result = f\"{directory_path}plot_gal3.svg\"\n",
    "    plt.savefig(result)\n",
    "    plt.show()\n",
    "\n",
    "    return df_norm, df_cleaned_sorted\n",
    "\n",
    "\n",
    "def curves_clustering(df_norm, cluster_number = 10):\n",
    "    clustering = AgglomerativeClustering(n_clusters=cluster_number)\n",
    "    clustering.fit(df_norm)\n",
    "    experiment_labels = clustering.labels_\n",
    "    df_norm['cluster'] = experiment_labels\n",
    "    # Print the labels\n",
    "    #print(experiment_labels)\n",
    "    for cluster_num in df_norm['cluster'].unique():\n",
    "        # Filter data for the current cluster\n",
    "        cluster_data = df_norm[df_norm['cluster'] == cluster_num]\n",
    "        \n",
    "        # Plot the data for the current cluster\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for idx, row in cluster_data.iterrows():\n",
    "            plt.plot(range(len(row)-1), row[:-1], label=idx)  # Exclude the last column 'cluster' from plotting\n",
    "        plt.title(f'Cluster {cluster_num} Data')\n",
    "        plt.xlabel('distance (pixels)')\n",
    "        plt.ylabel('RawIntDen / Area')\n",
    "        result = f\"{directory_path}plot_{cluster_num}.svg\"\n",
    "        plt.savefig(result)        #plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401fcb70-53dc-413a-aa5d-124b136c248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your parent directory\n",
    "directory_path = '/Users/MrWor/Documents/imaging/20240808 thplc3 h37 gal3 osbp alix_sc chmp4b/osbp/6h/'\n",
    "\n",
    "#Creation of different directory for outputs\n",
    "bact_path = directory_path + \"bact/\"\n",
    "if not os.path.exists(bact_path):\n",
    "    os.makedirs(bact_path)\n",
    "measurement_path = directory_path + \"measurement/\"\n",
    "if not os.path.exists(measurement_path):\n",
    "    os.makedirs(measurement_path)\n",
    "channels_path = directory_path + \"channels/\"\n",
    "if not os.path.exists(channels_path):\n",
    "    os.makedirs(channels_path)\n",
    "voronoi_path = directory_path + \"voronoi/\"\n",
    "if not os.path.exists(voronoi_path):\n",
    "    os.makedirs(voronoi_path)\n",
    "single_cells_path = directory_path + \"single_cells/\"\n",
    "if not os.path.exists(single_cells_path):\n",
    "    os.makedirs(single_cells_path)\n",
    "grouped_SC = directory_path + \"grouped_SC/\"\n",
    "if not os.path.exists(grouped_SC):\n",
    "    os.makedirs(grouped_SC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175777a-a4d5-421f-8160-63a8c75119b4",
   "metadata": {},
   "source": [
    "### this part is to get the different sub-stacks from the raw files useful for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07088f4a-2040-46a0-87e8-c0abfd0f866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "format = f'Tiff'\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "for file_path in file_list:\n",
    "    raw_image = image = ij.io().open(file_path)\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    LC3_channel = 2\n",
    "    channel = raw_image[:, :, LC3_channel, :]\n",
    "    lc3 = ij.py.to_imageplus(channel)\n",
    "    lc3.setDimensions(1, 11, 1)\n",
    "    #ij.ui().show(lc3)\n",
    "    result_path = f\"{channels_path}/LC3_channel_{corename}.tif\"\n",
    "    if os.path.exists(result_path):\n",
    "        os.remove(result_path)\n",
    "    ij.IJ.saveAs(lc3, \"Tiff\", ij.py.to_java(result_path))\n",
    "    \n",
    "    gal3_channel = 0\n",
    "    channel = raw_image[:, :, gal3_channel, :]\n",
    "    gal3 = ij.py.to_imageplus(channel)\n",
    "    gal3.setDimensions(1, 11, 1)\n",
    "    result_path = f\"{channels_path}/osbp_channel_{corename}.tif\"\n",
    "    if os.path.exists(result_path):\n",
    "        os.remove(result_path)    \n",
    "    ij.IJ.saveAs(gal3, \"Tiff\", ij.py.to_java(result_path))\n",
    "    \n",
    "    bact_channel = 1\n",
    "    channel = raw_image[:, :, bact_channel, :]\n",
    "    bact = ij.py.to_imageplus(channel)\n",
    "    bact.setDimensions(1, 11, 1)\n",
    "    result_path = f\"{bact_path}/bact_channel_{corename}.tif\"\n",
    "    if os.path.exists(result_path):\n",
    "        os.remove(result_path)    \n",
    "    ij.IJ.saveAs(bact, \"Tiff\", ij.py.to_java(result_path))\n",
    "\n",
    "    method = 'max'\n",
    "    nuclei_channel = 3\n",
    "    blue_channel = raw_image[:, :, nuclei_channel,:]\n",
    "    sigma = 1.5  # Adjust the value of sigma as needed\n",
    "    smoothed_image = ij.op().run(\"smooth\", blue_channel, sigma)\n",
    "    imp = ij.py.to_imageplus(smoothed_image) # convert the image into the imageplus type object needed for z-projection\n",
    "    # Z-projection\n",
    "    z_projector_result = ZProjector.run(imp, method)\n",
    "    z_collapsed_image = ij.py.from_java(z_projector_result)\n",
    "    z_collapsed_dataset = ij.py.to_dataset(z_collapsed_image)  \n",
    "    result_path = f\"{voronoi_path}/{corename}_max_nuclei_channel.tif\"\n",
    "    if os.path.exists(result_path):\n",
    "        os.remove(result_path)\n",
    "    ij.io().save(z_collapsed_dataset, result_path)\n",
    "    print(f\"Saving image {result_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53caae-1123-46de-aab3-e2b87ddbb148",
   "metadata": {},
   "source": [
    "# Voronoi segmentation to collect single cell background fluorescence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f777c6-832e-4bd0-9e0d-794b08dc05b2",
   "metadata": {},
   "source": [
    "### cellpose segmention\n",
    "This is to collect the nuclei ROIs that will serve as the base for the voronoi segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f7d5a-d835-436a-8d2c-2051984ced83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmentation using images ending with \"nuclei_channel.tif\"\n",
    "file_pattern = os.path.join(voronoi_path, \"*nuclei_channel.tif\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "model = models.CellposeModel(gpu=True, model_type='THP1_nuclei')\n",
    "for file_path in file_list:\n",
    "    imgs = io.imread(file_path)\n",
    "    channels = [[0,0]]\n",
    "    masks, flows, styles = model.eval(imgs, diameter=None, channels=channels)\n",
    "    io.save_to_png(imgs, masks, flows, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa1d29-2ee2-4c6e-b885-9858e9203284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is to obtain the ROIs from the cellpose segmentation step\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "for file_path in file_list:\n",
    "    f_name = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(f_name)[0]\n",
    "    image_path = f\"{voronoi_path}{corename}_max_nuclei_channel.tif\"\n",
    "    image_red = ij.io().open(image_path)\n",
    "    imp = ij.py.to_imageplus(image_red)\n",
    "    input_txt = Path(f\"{voronoi_path}/{corename}_max_nuclei_channel_cp_outlines.txt\")\n",
    "    txt_fh = open(input_txt, 'r')\n",
    "    for line in txt_fh:\n",
    "        xy = line.rstrip().split(\",\")\n",
    "        xy_coords = [int(element) for element in xy if element not in '']\n",
    "        x_coords = [int(element) for element in xy[::2] if element not in '']\n",
    "        y_coords = [int(element) for element in xy[1::2] if element not in '']\n",
    "        xcoords_jint = JArray(JInt)(x_coords)\n",
    "        ycoords_jint = JArray(JInt)(y_coords)\n",
    "        polygon_roi_instance = scyjava.jimport('ij.gui.PolygonRoi')\n",
    "        roi_instance = scyjava.jimport('ij.gui.Roi')\n",
    "        imported_polygon = polygon_roi_instance(xcoords_jint, ycoords_jint, len(x_coords), int(roi_instance.POLYGON))\n",
    "        imp.setRoi(imported_polygon)\n",
    "        rm.addRoi(imported_polygon)\n",
    "    ij.py.run_macro(\"roiManager('Select All');\")\n",
    "    rm.runCommand(\"Save\", f\"{voronoi_path}/\" + f\"{corename}_nuclei.zip\")\n",
    "    ij.py.run_macro(\"roiManager('Select All');\")\n",
    "    rm.runCommand(\"Delete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd131211-f8da-4c60-b820-6277fcde6b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voronoi segmentation on the nuclei channel\n",
    "for file_path in file_list:\n",
    "    f_name = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(f_name)[0]\n",
    "    image_path = f\"{voronoi_path}{corename}_max_nuclei_channel.tif\"\n",
    "    image= ij.io().open(image_path)\n",
    "    input_ROI = f\"{voronoi_path}{corename}_nuclei.zip\"\n",
    "    rm.open(input_ROI)\n",
    "    ij.ui().show(image)\n",
    "    #to better draw, apply and save ROIs, the image should be displayed:\n",
    "    imp = ij.py.to_imageplus(image) \n",
    "    roi_count = rm.getCount()\n",
    "    for i in range(roi_count):\n",
    "        rm.select(i)\n",
    "        shrinking = ij.IJ.run(\"Enlarge...\", \"enlarge=-1 pixel\")\n",
    "        rm.runCommand(\"update\")\n",
    "    rm.runCommand(\"Select All\")\n",
    "    rm.runCommand(\"XOR\")\n",
    "    rm.runCommand(\"Fill\")\n",
    "    rm.runCommand(\"Select All\")\n",
    "    rm.runCommand(\"XOR\")\n",
    "    ij.IJ.run(\"Clear Outside\")\n",
    "    rm.runCommand(\"Select All\")\n",
    "    rm.runCommand(\"Delete\")\n",
    "    ij.py.run_macro('setAutoThreshold(\"Default dark no-reset\");')\n",
    "    ij.IJ.run(\"Threshold...\")\n",
    "    ij.py.run_macro('setThreshold(5, 255);')\n",
    "    ij.py.run_macro('setOption(\"BlackBackground\", true);')\n",
    "    ij.IJ.run(\"Convert to Mask\", \"black\")\n",
    "    \n",
    "    voronoi = \"\"\"\n",
    "run(\"Set Measurements...\", \"center redirect=None decimal=1\");\n",
    "run(\"Analyze Particles...\",\"size=3-Infinity display clear\");\n",
    "//Resolution de l'image pwidth et pheight\n",
    "getPixelSize(unit, pw, ph, pd);\n",
    "//Voronio\n",
    "run(\"Voronoi\");\n",
    "setThreshold(0, 0,\"black & white\");\n",
    "\n",
    "//Wand to ROI Manager\n",
    "x=newArray(nResults);\n",
    "y=newArray(nResults);\n",
    "nbPoints=nResults;\n",
    "\n",
    "for (i=0; i<nbPoints; i++) {\n",
    "    x[i]=getResult(\"XM\",i)/pw;\n",
    "    y[i]=getResult(\"YM\",i)/ph;\n",
    "}\n",
    "for (i=0; i<nbPoints; i++) {\n",
    "    doWand(x[i], y[i], 156.0, \"Legacy\");\n",
    "    roiManager(\"Add\");\n",
    "}\n",
    "\n",
    "//Center of mass\n",
    "/*\n",
    "x=newArray(nResults);\n",
    "y=newArray(nResults);\n",
    "for (i=0; i<nResults; i++) {\n",
    "    x[i]=getResult(\"XM\",i)/pw;\n",
    "    y[i]=getResult(\"YM\",i)/ph;\n",
    "}\n",
    "*/\n",
    "makeSelection(\"point\", x, y);\n",
    "selectWindow(\"Results\");\n",
    "run(\"Close\");\n",
    "close(\"*\");\n",
    "\"\"\"\n",
    "    run_voronoi = ij.py.run_macro(voronoi)\n",
    "    ij.py.run_macro(\"roiManager('Select All');\")\n",
    "    rm.runCommand(\"Save\", f\"{voronoi_path}/\" + f\"{corename}_voronoi.zip\")\n",
    "    rm.runCommand(\"Delete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc07ff-d0df-49ec-9caa-477cd9c0dd7c",
   "metadata": {},
   "source": [
    "# getting single infected cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea63646-81da-48c1-8621-d92332074ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables needed for the future steps.\n",
    "# The threshold values concerns the bacterial channel for their detection. the 'low' and 'high' value must be determined in advance, easier done in fiji and the \n",
    "# adjust threshold function. \n",
    "# The threshold size is the size limit from which the bacteria will be detected\n",
    "threshold_low = 10 \n",
    "threshold_high = 255\n",
    "threshold_size = 0.1\n",
    "# these values are to set the scale of the images\n",
    "distance = 1024 \n",
    "known = 224.48\n",
    "unit = \"Âµm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529588a-dddd-4232-8371-5bd05a0968f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_bacteria_area(bact_path, directory_path, threshold_low, threshold_high, distance, known, unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ff48f-8eae-4158-a0c6-3529cb6e0e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_number = 11 # Change this to the actual slice number in your image\n",
    "slice_distance = 1  # Change this to the actual distance between your slices. The unit here is in micrometers\n",
    "#file_pattern = os.path.join(directory_path, \"*area_summary.csv\")\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "final_results_path = f\"{directory_path}final_results/\"\n",
    "if not os.path.exists(final_results_path):\n",
    "    os.makedirs(final_results_path)\n",
    "for file_path in file_list:\n",
    "    # Read the DataFrame.\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    csv_path = f\"{bact_path}{corename}_area_summary.csv\"\n",
    "    df = pandas.read_csv(csv_path)\n",
    "\n",
    "    # Calculate the sum of the \"Total Area\" for each pattern of the \"Slice\" column.\n",
    "    df1 = calculate_total_volume_per_cell(df)\n",
    "    \n",
    "    #f_name = os.path.splitext(f_name)[0]\n",
    "    output_path = f\"{final_results_path}/{corename}_burden.csv\"\n",
    "    df1.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c88ba-feb2-42f3-bd2a-1292568372b9",
   "metadata": {},
   "source": [
    "### Single cell isolation\n",
    "This will duplicate every infected cells (or showing a volume of bacteria above the 'size_limit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff66f22-0e13-40da-ae7f-1aae3d2d3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the names of the channel of interests\n",
    "cois = ['bact_channel','osbp_channel','LC3_channel']\n",
    "\n",
    "#function to isolate single cell signals\n",
    "w = scyjava.jimport('ij.WindowManager')\n",
    "single_cell_isolation(cois, directory_path, bact_path, voronoi_path, channels_path, size_limit = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8927bc37-8e41-41eb-bc13-c813e9db8d83",
   "metadata": {},
   "source": [
    "# Single cell fluorescence measurement\n",
    "this step is to collect the fluorescence intensity in the cells, that can serve as a background value to substrack to the MCV fluorescence. This could eventually improve the classification of bacteria. But this step is not mandatory and the numbers should be compared between the raw and substracted fluorescence bacteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1e374d-0d43-489a-8bf3-c1930b7d0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_low = 1\n",
    "threshold_high = 255\n",
    "distance = 1024 \n",
    "known_scale = 224.48\n",
    "unit = \"Âµm\"\n",
    "cois = ['osbp_channel','LC3_channel']\n",
    "w = scyjava.jimport('ij.WindowManager')\n",
    "single_cell_fluorescence(cois, directory_path, voronoi_path, channels_path, distance, known_scale, unit, size_limit = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b7a630-73e4-40af-89bc-ec414bdbed39",
   "metadata": {},
   "source": [
    "# single cell bacteria detection and measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7fa0c-91d9-482f-b125-a05f40ba73dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trackmate settings\n",
    "\n",
    "dsettings = { # specify parameters for the detection step in Trackmate (Threshold Detector)\n",
    "    'TARGET_CHANNEL' : ij.py.to_java(1),\n",
    "    'SIMPLIFY_CONTOURS' : False,\n",
    "    'INTENSITY_THRESHOLD' : 10.0,\n",
    "}\n",
    "quality_filter = 50\n",
    "tsettings = { # specify parameters for the tracking step in Trackmate (LAP Tracker)\n",
    "    'LINKING_MAX_DISTANCE' : 10.0,\n",
    "    'ALLOW_GAP_CLOSING' : True,\n",
    "    'GAP_CLOSING_MAX_DISTANCE' : 4.0,\n",
    "    'MAX_FRAME_GAP' : ij.py.to_java(2),\n",
    "    'ALLOW_TRACK_SPLITTING' : False,\n",
    "    'SPLITTING_MAX_DISTANCE' : 15.0,\n",
    "    'ALLOW_TRACK_MERGING' : False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7e9e5d-cc94-4933-a00d-cc3600190dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_low = 10\n",
    "threshold_high = 255\n",
    "threshold_size = 0.1\n",
    "distance = 1024 \n",
    "known = 224.48\n",
    "unit = \"Âµm\"\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    single_cells_image_path = f\"{single_cells_path}{corename}/\" \n",
    "    get_bact_rois(single_cells_image_path) # Collect Bacteria ROIs using particle detection of Fiji\n",
    "    track_bacteria(directory_path, single_cells_image_path, dsettings, quality_filter, tsettings, display=False) # detect bacteria centroid using trackmate\n",
    "    merge_trackmate_rois(single_cells_image_path, directory_path, grouped_SC) # Assigment of a single ROI from the pool in the first step to the centroid detected in trackmate\n",
    "    apply_bact_overlays(single_cells_image_path, grouped_SC)# Overla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677dab7-924e-4e68-8df7-11783afe1f12",
   "metadata": {},
   "source": [
    "### Saving ROIs in a dedicated folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade7df4-9893-459b-b2d7-dc62bec6d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename_image = os.path.splitext(basename)[0]\n",
    "    single_cells_image_path = f\"{single_cells_path}{corename_image}/\"\n",
    "    saving_rois(single_cells_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbdab48-d4d8-480f-a953-d10772b1308f",
   "metadata": {},
   "source": [
    "### circle measurement around bacteria in single cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f3aa4-1431-4588-a88d-db385ce8059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 1024 \n",
    "known_scale = 224.48\n",
    "unit = \"Âµm\"\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "# enters the channels in your image\n",
    "cois = ['osbp_channel', 'LC3_channel', 'bact_channel']\n",
    "bact_channel = cois[2]\n",
    "set_string = f'Set Measurements...'\n",
    "measure_string = f'mean area integrated stack redirect=None decimal=2'\n",
    "ij.IJ.run(set_string, measure_string)\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    single_cells_image_path = f\"{single_cells_path}{corename}/\"\n",
    "    file_pattern2 = os.path.join(single_cells_image_path, \"*.tif\")\n",
    "    file_list2 = glob.glob(file_pattern2)\n",
    "    for image in file_list2:\n",
    "        if not image.endswith('overlay.tif'):\n",
    "            basename2 = os.path.basename(image)\n",
    "            corename2 = os.path.splitext(basename2)[0]\n",
    "            if corename2.startswith(cois[0]):\n",
    "                channel = cois[0]\n",
    "                f_name = corename2.split(f\"{channel}_\")[1]\n",
    "                bact_roi_path = f\"{single_cells_image_path}rois_bact/{f_name}\"\n",
    "                imp = ij.IJ.openImage(image)\n",
    "                print(f\"opening {corename2}\")\n",
    "                imp.show()\n",
    "                ij.IJ.run(imp, \"Select None\", \"\")\n",
    "                circlesofhell(bact_roi_path, channel, distance, known_scale, unit, imp) # This is the circle workflow\n",
    "                ij.py.run_macro('close(\"*\");')\n",
    "            elif corename2.startswith(cois[1]):\n",
    "                channel = cois[1]\n",
    "                f_name = corename2.split(f\"{channel}_\")[1]\n",
    "                bact_roi_path = f\"{single_cells_image_path}rois_bact/{f_name}\"\n",
    "                imp = ij.IJ.openImage(image)\n",
    "                print(f\"opening {corename2}\")\n",
    "                imp.show()\n",
    "                ij.IJ.run(imp, \"Select None\", \"\") \n",
    "                circlesofhell(bact_roi_path, channel, distance, known_scale, unit, imp)\n",
    "                ij.py.run_macro('close(\"*\");')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc72c762-9ba7-443f-83ab-f632cc01492d",
   "metadata": {},
   "source": [
    "# concatenation of CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc6a22d-3b77-462a-a7a9-475e21c11c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "df_lc3_list = []\n",
    "df_gal3_list = []\n",
    "\n",
    "df_lc3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_lc3_list.append(df_lc3['circle'])\n",
    "df_gal3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_gal3_list.append(df_lc3['circle'])\n",
    "\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    bact_roi_path = f\"{single_cells_path}{corename}/rois_bact/\"\n",
    "    for cells in os.listdir(bact_roi_path):\n",
    "        csv_path = f\"{bact_roi_path}{cells}/\"\n",
    "        file_pattern2 = os.path.join(csv_path, \"*.csv\")\n",
    "        file_list2 = glob.glob(file_pattern2)\n",
    "        for csv in file_list2:\n",
    "            if csv.endswith('LC3_channel.csv'):\n",
    "                df= pandas.read_csv(csv)\n",
    "                norm_raw = []\n",
    "                basename = os.path.basename(csv)\n",
    "                roi_number = basename.split(\"_\")[0]\n",
    "                cell_name = f\"{cells}_{roi_number}\"\n",
    "                for i in range(len(df)):\n",
    "                    ratio = df['RawIntDen'][i] / df['Area'][i]\n",
    "                    norm_raw.append(ratio)\n",
    "                df[cell_name] = norm_raw   \n",
    "                df_lc3_list.append(df[cell_name])\n",
    "    \n",
    "            if csv.endswith('osbp_channel.csv'):\n",
    "                df= pandas.read_csv(csv)\n",
    "                norm_raw = []\n",
    "                basename = os.path.basename(csv)\n",
    "                roi_number = basename.split(\"_\")[0]\n",
    "                cell_name = f\"{cells}_{roi_number}\"\n",
    "                for i in range(len(df)):\n",
    "                    ratio = df['RawIntDen'][i] / df['Area'][i]\n",
    "                    norm_raw.append(ratio)\n",
    "                df[cell_name] = norm_raw \n",
    "                df_gal3_list.append(df[cell_name])\n",
    "                \n",
    "    result_lc3 = pandas.concat(df_lc3_list, axis=1)\n",
    "    result_gal3 = pandas.concat(df_gal3_list, axis=1)    \n",
    "    result_lc3.to_csv(f\"{directory_path}LC3_numbers_Rawint_area.csv\")\n",
    "    result_gal3.to_csv(f\"{directory_path}osbp_numbers_Rawint_area.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a894f-3ec0-4088-8093-bf1867fbea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "df_lc3_list = []\n",
    "df_gal3_list = []\n",
    "\n",
    "df_lc3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_lc3_list.append(df_lc3['circle'])\n",
    "df_gal3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_gal3_list.append(df_lc3['circle'])\n",
    "\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    bact_roi_path = f\"{single_cells_path}{corename}/rois_bact/\"\n",
    "    for cells in os.listdir(bact_roi_path):\n",
    "        csv_path = f\"{bact_roi_path}{cells}/\"\n",
    "        file_pattern2 = os.path.join(csv_path, \"*.csv\")\n",
    "        file_list2 = glob.glob(file_pattern2)\n",
    "        for csv in file_list2:\n",
    "            if csv.endswith('LC3_channel.csv'):\n",
    "                df= pandas.read_csv(csv)\n",
    "                norm_raw = []\n",
    "                basename = os.path.basename(csv)\n",
    "                roi_number = basename.split(\"_\")[0]\n",
    "                cell_name = f\"{cells}_{roi_number}\"\n",
    "                for i in range(len(df)):\n",
    "                    prout = df['Mean'][i]\n",
    "                    norm_raw.append(prout)\n",
    "                df[cell_name] = norm_raw   \n",
    "                df_lc3_list.append(df[cell_name])\n",
    "    \n",
    "            if csv.endswith('osbp_channel.csv'):\n",
    "                df= pandas.read_csv(csv)\n",
    "                norm_raw = []\n",
    "                basename = os.path.basename(csv)\n",
    "                roi_number = basename.split(\"_\")[0]\n",
    "                cell_name = f\"{cells}_{roi_number}\"\n",
    "                for i in range(len(df)):\n",
    "                    prout = df['Mean'][i]\n",
    "                    norm_raw.append(prout)\n",
    "                df[cell_name] = norm_raw  \n",
    "                df_gal3_list.append(df[cell_name])\n",
    "                \n",
    "    result_lc3 = pandas.concat(df_lc3_list, axis=1)\n",
    "    result_gal3 = pandas.concat(df_gal3_list, axis=1)    \n",
    "    result_lc3.to_csv(f\"{directory_path}LC3_numbers_MFI.csv\")\n",
    "    result_gal3.to_csv(f\"{directory_path}osbp_numbers_MFI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8507a-1838-4072-9c64-33a4a8a85df1",
   "metadata": {},
   "source": [
    "### this one below is to use only on Gal3 to substract the average value of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a538bb-080d-48c7-a876-996325aceafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "df_lc3_list = []\n",
    "df_gal3_list = []\n",
    "\n",
    "df_lc3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_lc3_list.append(df_lc3['circle'])\n",
    "df_gal3 = pandas.DataFrame({'circle': [1, 2, 3, 4, 5, 6]})\n",
    "df_gal3_list.append(df_lc3['circle'])\n",
    "\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    csv_path = f\"{channels_path}gal3_channel_{corename}_final_number.csv\"\n",
    "    df = pandas.read_csv(csv_path)\n",
    "    bact_roi_path = f\"{single_cells_path}{corename}/rois_bact/\"\n",
    "    cell_list = os.listdir(bact_roi_path)\n",
    "    for i in range(len(df)):\n",
    "        cell_name = df['cell_ID'][i]\n",
    "        gauche = cell_name.split(\"_\")[2]\n",
    "        droite = cell_name.split(\"_\")[3]\n",
    "        folder_name = f\"{gauche}_{droite}\"\n",
    "        folder_path = f\"{bact_roi_path}{folder_name}/\"\n",
    "        csv_pattern  = os.path.join(folder_path, \"*gal3_channel.csv\")\n",
    "        csv_list = glob.glob(csv_pattern)\n",
    "        for csv in csv_list:\n",
    "            df2 = pandas.read_csv(csv)\n",
    "            basename = os.path.basename(csv)\n",
    "            roi_number = basename.split(\"_\")[0]\n",
    "            cell_name = f\"{folder_name}_{roi_number}\"\n",
    "            norm_raw = []\n",
    "            for n in range(len(df2)):\n",
    "                ratio = df2['RawIntDen'][n] / df2['Area'][n]\n",
    "                norm_ratio = ratio - df['RawIntDen/Area'][i]\n",
    "                norm_raw.append(norm_ratio)\n",
    "            df2[cell_name] = norm_raw\n",
    "            df_gal3_list.append(df2[cell_name])\n",
    "\n",
    "    result_gal3 = pandas.concat(df_gal3_list, axis=1)\n",
    "    result_gal3.to_csv(f\"{directory_path}gal3_numbers_norm.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc6007e-7df5-4de4-84b7-77cef4799873",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = f\"{channels_path}gal3_channel_Experiment-2168_final_number.csv\"\n",
    "df = pandas.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5313f2-4fa4-4b49-8252-3f84c17b69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prout = df['cell_ID'][1]\n",
    "fessegauche = prout.split(\"_\")[2]\n",
    "fessedroite = prout.split(\"_\")[3]\n",
    "fesses = f\"{fessegauche}_{fessedroite}\"\n",
    "print(fesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8ad01-0502-43df-b6a7-8806c3a5da95",
   "metadata": {},
   "source": [
    "# saving a montage of each detected phagosome for visual curation of the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481edebe-2361-4990-95bc-15b126a86d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cois = ['bact_channel', 'osbp_channel','LC3_channel']\n",
    "w = scyjava.jimport('ij.WindowManager')\n",
    "single_composite_isolation(cois, directory_path, voronoi_path, size_limit = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c8e07-64a0-4763-9a76-ff483b35ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a montage of each MCV\n",
    "file_pattern = os.path.join(directory_path, \"*.czi\")\n",
    "file_list = glob.glob(file_pattern)\n",
    "w = scyjava.jimport('ij.WindowManager')\n",
    "for file_path in file_list:\n",
    "    basename = os.path.basename(file_path)\n",
    "    corename = os.path.splitext(basename)[0]\n",
    "    bact_roi_path = f\"{single_cells_path}{corename}/rois_bact/\"\n",
    "    for folder in os.listdir(bact_roi_path):\n",
    "        image_folder = f\"{bact_roi_path}/{folder}/\"\n",
    "        image_path = f\"{image_folder}{folder}.tif\"\n",
    "        imp = ij.IJ.openImage(image_path)\n",
    "        imp.show()\n",
    "        imp.setDisplayMode(1)\n",
    "        imp.setC(1)\n",
    "        ij.IJ.run(imp, \"Red\", \"\")\n",
    "        ij.py.run_macro(\"setMinAndMax(0, 100);\")\n",
    "        imp.setC(2)\n",
    "        ij.IJ.run(imp, \"Blue\", \"\")\n",
    "        ij.py.run_macro(\"setMinAndMax(0, 100);\")\n",
    "        imp.setC(3)\n",
    "        ij.IJ.run(imp, \"Green\", \"\")\n",
    "        ij.py.run_macro(\"setMinAndMax(0, 100);\")\n",
    "        imp.setC(4)\n",
    "        ij.IJ.run(imp, \"Grays\", \"\")\n",
    "        #ij.IJ.run(imp, \"RGB Color\", \"slices\")\n",
    "        roi_pattern = os.path.join(image_folder, \"*.roi\")\n",
    "        roi_list = glob.glob(roi_pattern)\n",
    "        for roi in roi_list:\n",
    "            roi_basename = os.path.basename(roi)\n",
    "            roi_corename = os.path.splitext(roi_basename)[0]\n",
    "            open_roi = rm.open(roi)    \n",
    "            roi = rm.getRoi(0)\n",
    "            selected = rm.select(0)\n",
    "            x = roi.getContourCentroid()[0]\n",
    "            y = roi.getContourCentroid()[1]\n",
    "            square = imp.setRoi(int(x-20), int(y-20), 40, 40)\n",
    "            added = rm.addRoi(square)\n",
    "            roi2 = rm.getRoi(1)\n",
    "            roi3 = rm.select(1)\n",
    "            square_name = f\"{folder}_{roi_corename}\"\n",
    "            ij.IJ.run(\"Duplicate...\", f\"title={str(square_name)}\")\n",
    "            new_vid =  w.getImage(str(square_name))\n",
    "            ij.IJ.run(new_vid, \"Make Montage...\", \"columns=4 rows=1 scale=2 border=1\")\n",
    "            new_montage =  w.getImage(\"Montage\")\n",
    "            output_path = f\"{measurement_path}{square_name}.tif\"\n",
    "            if os.path.exists(output_path):\n",
    "                os.remove(output_path)\n",
    "            ij.IJ.save(new_montage, output_path)\n",
    "            rm.reset()\n",
    "            w.getImage(\"Montage\").close()\n",
    "            w.getImage(str(square_name)).close()\n",
    "            ij.IJ.selectWindow(imp.getTitle())\n",
    "        ij.py.run_macro('close(\"*\");')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0170e00-975b-43b9-b5bb-9066e1d2d5bf",
   "metadata": {},
   "source": [
    "# Classification of the stainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaa58c-8cf9-4838-8eac-09a4449a4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_lc3 = f\"{directory_path}LC3_numbers_Rawint_area.csv\"\n",
    "csv_gal3 = f\"{directory_path}osbp_numbers_Rawint_area.csv\"\n",
    "df_lc3 = pandas.read_csv(csv_lc3)\n",
    "df_gal3 = pandas.read_csv(csv_gal3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a013b7-5b24-4c94-8d3f-27b5d138cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning LC3 signals\n",
    "df_lc3_norm, df_lc3_cleaned_sorted = df_cleaning(df_lc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960c65d-b3ca-4d1e-910f-66e976571c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering the signal using sklearn clustering method\n",
    "clustering = curves_clustering(df_lc3_norm, cluster_number = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a582b0-b78b-46fb-9d7d-d32c0a396c02",
   "metadata": {},
   "source": [
    "### Visualization of specific cluster in scrollable window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2d498-97f8-47f5-8e15-dc9fea575de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to define which cluster to vizualize. It will grab the montage images for the designated cluster group and display them. \n",
    "image_list = []\n",
    "cluster_num = 5\n",
    "for i in range(len(df_lc3_norm)):\n",
    "    if df_lc3_norm['cluster'][i] == cluster_num:\n",
    "        image = df_lc3_norm.index[i]\n",
    "        image_path = Path(f\"{measurement_path}{image}.tif\").as_posix()\n",
    "        image_list.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b7563-f0a7-4a92-b9f2-721109e5fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to display the images bound to the cluster defined above. \n",
    "# Still need to find a way to open this as a separated window that does not block the whole session so we can display multiple windows with multiple outputs.\n",
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, image_list):\n",
    "        super().__init__()\n",
    "        self.image_list = image_list\n",
    "        self.window()\n",
    "    \n",
    "    def window(self):\n",
    "        self.scroll = QScrollArea()\n",
    "        self.win = QWidget()\n",
    "        self.grid = QGridLayout()\n",
    "\n",
    "        num_images = len(self.image_list)\n",
    "        num_columns = 4  # Fixed number of columns\n",
    "        num_rows = (num_images + num_columns - 1) // num_columns  # Calculate number of rows dynamically\n",
    "\n",
    "        n = 0\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_columns):\n",
    "                if n < num_images:\n",
    "                    file = self.image_list[n]\n",
    "                    pixmap = QPixmap(file)\n",
    "                    pixmap2 = pixmap.scaled(500, 200, Qt.KeepAspectRatio)\n",
    "                    label = QLabel(pixmap=pixmap2)\n",
    "                    self.grid.addWidget(label, i, j)\n",
    "                    n += 1\n",
    "    \n",
    "        self.win.setLayout(self.grid)\n",
    "        self.scroll.setWidgetResizable(True)\n",
    "        self.scroll.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setWidget(self.win)\n",
    "        self.setCentralWidget(self.scroll)\n",
    "        self.setGeometry(0, 0, 2300, 1000)\n",
    "        self.setWindowTitle('Image Viewer')\n",
    "        self.show()\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    main = MainWindow(image_list)\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681277b6-21c9-401c-a609-273ff6181b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_positives_lc3 = [5, 4, 2, 8, 0, 9, 7, 6]\n",
    "clusters_negatives_lc3 = [3, 1]\n",
    "df_lc3_norm.loc[df_lc3_norm['cluster'].isin(clusters_positives_lc3), 'cluster'] = 10\n",
    "df_lc3_norm.loc[df_lc3_norm['cluster'].isin(clusters_negatives_lc3), 'cluster'] = 11\n",
    "df_lc3_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffaf1fb-ebed-4ce4-8a62-c131da8929cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_3 = df_lc3_norm[df_lc3_norm['cluster'] == 4].drop(columns=['cluster'])\n",
    "df_cluster_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f626a-9805-4cfa-8db7-f60e01aadd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the clustering function on the filtered data\n",
    "clustering = curves_clustering(df_cluster_3, cluster_number = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae565b20-6e5b-400f-b9eb-0908c2658a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "cluster_num = 2\n",
    "for i in range(len(df_cluster_3)):\n",
    "    if df_cluster_3['cluster'][i] == cluster_num:\n",
    "        image = df_cluster_3.index[i]\n",
    "        image_path = Path(f\"{measurement_path}{image}.tif\").as_posix()\n",
    "        image_list.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc2674-a690-444e-8f47-a59e28b9c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, image_list):\n",
    "        super().__init__()\n",
    "        self.image_list = image_list\n",
    "        self.window()\n",
    "    \n",
    "    def window(self):\n",
    "        self.scroll = QScrollArea()\n",
    "        self.win = QWidget()\n",
    "        self.grid = QGridLayout()\n",
    "\n",
    "        num_images = len(self.image_list)\n",
    "        num_columns = 4  # Fixed number of columns\n",
    "        num_rows = (num_images + num_columns - 1) // num_columns  # Calculate number of rows dynamically\n",
    "\n",
    "        n = 0\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_columns):\n",
    "                if n < num_images:\n",
    "                    file = self.image_list[n]\n",
    "                    pixmap = QPixmap(file)\n",
    "                    pixmap2 = pixmap.scaled(500, 200, Qt.KeepAspectRatio)\n",
    "                    label = QLabel(pixmap=pixmap2)\n",
    "                    self.grid.addWidget(label, i, j)\n",
    "                    n += 1\n",
    "    \n",
    "        self.win.setLayout(self.grid)\n",
    "        self.scroll.setWidgetResizable(True)\n",
    "        self.scroll.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setWidget(self.win)\n",
    "        self.setCentralWidget(self.scroll)\n",
    "        self.setGeometry(0, 0, 2300, 1000)\n",
    "        self.setWindowTitle('Image Viewer')\n",
    "        self.show()\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    main = MainWindow(image_list)\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831293d-eb0b-429c-a470-40c7310dce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_positives_lc3_2 = [1]\n",
    "clusters_negatives_lc3_2 = [0, 2]\n",
    "df_cluster_3.loc[df_cluster_3['cluster'].isin(clusters_positives_lc3_2), 'cluster'] = 10\n",
    "df_cluster_3.loc[df_cluster_3['cluster'].isin(clusters_negatives_lc3_2), 'cluster'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3988dd60-1833-4460-ab56-ae1d4b5ab62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_3.rename(columns={'cluster': 'new_cluster'}, inplace=True)\n",
    "\n",
    "# Update the original dataframe with the new cluster labels for cluster 4\n",
    "df_lc3_norm.loc[df_lc3_norm['cluster'] == 4, 'cluster'] = df_cluster_3['new_cluster'].values\n",
    "#df_gal3_norm.to_csv(f\"{directory_path}df_gal3_norm.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f68655-4f2f-4db3-8b63-ad0fa25f3b14",
   "metadata": {},
   "source": [
    "### same workflow for the second marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc593d6e-5ccb-4a67-8560-a9ca167006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal3_norm, df_gal3_cleaned_sorted = df_cleaning(df_gal3)\n",
    "clustering = curves_clustering(df_gal3_norm, cluster_number = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55417f12-578e-4118-95bd-481a616c1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "cluster_num = 4\n",
    "for i in range(len(df_gal3_norm)):\n",
    "    if df_gal3_norm['cluster'][i] == cluster_num:\n",
    "        image = df_gal3_norm.index[i]\n",
    "        image_path = Path(f\"{measurement_path}{image}.tif\").as_posix()\n",
    "        image_list.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7bb4b-4336-4616-9ed5-4285e3f5c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, image_list):\n",
    "        super().__init__()\n",
    "        self.image_list = image_list\n",
    "        self.window()\n",
    "    \n",
    "    def window(self):\n",
    "        self.scroll = QScrollArea()\n",
    "        self.win = QWidget()\n",
    "        self.grid = QGridLayout()\n",
    "\n",
    "        num_images = len(self.image_list)\n",
    "        num_columns = 4  # Fixed number of columns\n",
    "        num_rows = (num_images + num_columns - 1) // num_columns  # Calculate number of rows dynamically\n",
    "\n",
    "        n = 0\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_columns):\n",
    "                if n < num_images:\n",
    "                    file = self.image_list[n]\n",
    "                    pixmap = QPixmap(file)\n",
    "                    pixmap2 = pixmap.scaled(500, 200, Qt.KeepAspectRatio)\n",
    "                    label = QLabel(pixmap=pixmap2)\n",
    "                    self.grid.addWidget(label, i, j)\n",
    "                    n += 1\n",
    "    \n",
    "        self.win.setLayout(self.grid)\n",
    "        self.scroll.setWidgetResizable(True)\n",
    "        self.scroll.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setWidget(self.win)\n",
    "        self.setCentralWidget(self.scroll)\n",
    "        self.setGeometry(0, 0, 2300, 1000)\n",
    "        self.setWindowTitle('Image Viewer')\n",
    "        self.show()\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    main = MainWindow(image_list)\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78ba084-6d86-428c-8b67-1c8ffaffe20b",
   "metadata": {},
   "source": [
    "### Reclustering insatisfying groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2539827-f794-4008-8d13-8aaff1e09d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_positives_gal3 = [2, 1, 4, 6, 7, 5]\n",
    "clusters_negatives_gal3 = [3, 0, 9, 8]\n",
    "df_gal3_norm.loc[df_gal3_norm['cluster'].isin(clusters_positives_gal3), 'cluster'] = 10\n",
    "df_gal3_norm.loc[df_gal3_norm['cluster'].isin(clusters_negatives_gal3), 'cluster'] = 11\n",
    "df_gal3_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5019bf-ef8c-4174-951a-ea840295fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_3 = df_gal3_norm[df_gal3_norm['cluster'] == 1].drop(columns=['cluster'])\n",
    "df_cluster_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa8a70-dfc6-4fc7-a8d0-faab7d89dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the clustering function on the filtered data\n",
    "clustering = curves_clustering(df_cluster_3, cluster_number = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8721e3-d169-4d33-91df-4a01ac317ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "cluster_num = 0\n",
    "for i in range(len(df_cluster_3)):\n",
    "    if df_cluster_3['cluster'][i] == cluster_num:\n",
    "        image = df_cluster_3.index[i]\n",
    "        image_path = Path(f\"{measurement_path}{image}.tif\").as_posix()\n",
    "        image_list.append(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4324a5-3aa4-4116-9b03-895bf9e6d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    def __init__(self, image_list):\n",
    "        super().__init__()\n",
    "        self.image_list = image_list\n",
    "        self.window()\n",
    "    \n",
    "    def window(self):\n",
    "        self.scroll = QScrollArea()\n",
    "        self.win = QWidget()\n",
    "        self.grid = QGridLayout()\n",
    "\n",
    "        num_images = len(self.image_list)\n",
    "        num_columns = 4  # Fixed number of columns\n",
    "        num_rows = (num_images + num_columns - 1) // num_columns  # Calculate number of rows dynamically\n",
    "\n",
    "        n = 0\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_columns):\n",
    "                if n < num_images:\n",
    "                    file = self.image_list[n]\n",
    "                    pixmap = QPixmap(file)\n",
    "                    pixmap2 = pixmap.scaled(500, 200, Qt.KeepAspectRatio)\n",
    "                    label = QLabel(pixmap=pixmap2)\n",
    "                    self.grid.addWidget(label, i, j)\n",
    "                    n += 1\n",
    "    \n",
    "        self.win.setLayout(self.grid)\n",
    "        self.scroll.setWidgetResizable(True)\n",
    "        self.scroll.setVerticalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setHorizontalScrollBarPolicy(Qt.ScrollBarAlwaysOn)\n",
    "        self.scroll.setWidget(self.win)\n",
    "        self.setCentralWidget(self.scroll)\n",
    "        self.setGeometry(0, 0, 2300, 1000)\n",
    "        self.setWindowTitle('Image Viewer')\n",
    "        self.show()\n",
    "\n",
    "def main():\n",
    "    app = QApplication(sys.argv)\n",
    "    main = MainWindow(image_list)\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66697f41-aac6-4b53-b515-a97ab6a3787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_positives_gal3_2 = [1]\n",
    "clusters_negatives_gal3_2 = [0, 2]\n",
    "df_cluster_3.loc[df_cluster_3['cluster'].isin(clusters_positives_gal3_2), 'cluster'] = 10\n",
    "df_cluster_3.loc[df_cluster_3['cluster'].isin(clusters_negatives_gal3_2), 'cluster'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdca6a1-6f89-4a18-a798-4e81215bac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_3.rename(columns={'cluster': 'new_cluster'}, inplace=True)\n",
    "\n",
    "# Update the original dataframe with the new cluster labels for cluster 4\n",
    "df_gal3_norm.loc[df_gal3_norm['cluster'] == 1, 'cluster'] = df_cluster_3['new_cluster'].values\n",
    "#df_gal3_norm.to_csv(f\"{directory_path}df_gal3_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42391a5-27aa-49cc-b07e-ab747d555916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal3_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a2547-f202-4230-bdfd-b71049a1f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_gal3_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37853efa-332f-4ae3-b3a3-1af5e2d8ee18",
   "metadata": {},
   "source": [
    "### Quantification of the frequency of \"positive\" vs \"negative\" phagosomes for the different markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3273917-9bc3-4e68-9857-a35bdeffcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the cluster number matching each category\n",
    "clusters_positives_lc3 = [10]\n",
    "clusters_negatives_lc3 = [11]\n",
    "clusters_positives_gal3 = [10]\n",
    "clusters_negatives_gal3 = [11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3ab315-ffec-4f71-a776-3d6f82cf36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each phagosome\n",
    "lc3_positive = []\n",
    "gal3_positive = []\n",
    "double_positive = []\n",
    "negatives = []\n",
    "\n",
    "for i in range(len(df_lc3_norm)):\n",
    "    image = df_lc3_norm.index[i]\n",
    "    if df_lc3_norm['cluster'][i] in clusters_positives_lc3 and df_gal3_norm['cluster'][i] in clusters_positives_gal3:\n",
    "        double_positive.append(image)\n",
    "    elif df_lc3_norm['cluster'][i] in clusters_positives_lc3 and df_gal3_norm['cluster'][i] in clusters_negatives_gal3:\n",
    "        lc3_positive.append(image)\n",
    "            \n",
    "    elif df_lc3_norm['cluster'][i] in clusters_negatives_lc3 and df_gal3_norm['cluster'][i] in clusters_positives_gal3:\n",
    "        gal3_positive.append(image)\n",
    "    else:\n",
    "        negatives.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ba183-377b-4047-87bf-7b6ecdda6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation of a table summarizing each category\n",
    "total_images = len(df_lc3_norm)\n",
    "df = pandas.DataFrame({\n",
    "    'category': ['lc3_positive', 'osbp_positive', 'double_positive', 'negatives'],\n",
    "    'count': [len(lc3_positive), len(gal3_positive), len(double_positive), len(negatives)]\n",
    "})\n",
    "df['% total'] = (df['count'] / total_images) * 100\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9aff49-44d6-40c8-be30-228be8f38701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gal3_norm.to_csv(f\"{directory_path}df_gal3_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df3bfd6-c78e-4dac-a3ce-7d801f5ce259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export of the table\n",
    "df.to_csv(f\"{directory_path}Lc3_osbp_%quantif.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25b609-a515-4b53-ac87-825e8e4be961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb07c13-547a-4cea-b602-c34ff2a9cee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a034fe-85e8-4663-9826-78f89dc148b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_4 = df_gal_norm[df_gal_norm['cluster'] == 4].drop(columns=['cluster'])\n",
    "\n",
    "# Run the clustering function on the filtered data\n",
    "curves_clustering(df_cluster_4, cluster_number = 3)  # Adjust the number of clusters\n",
    "df_cluster_4['new_cluster'] = clustering.fit(df_cluster_4)\n",
    "\n",
    "# Update the original dataframe with the new cluster labels for cluster 4\n",
    "df_gal_norm.loc[df_gal_norm['cluster'] == 4, 'cluster'] = df_cluster_4['new_cluster'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
